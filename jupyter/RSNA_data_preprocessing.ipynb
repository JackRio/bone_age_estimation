{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-15T07:46:52.496976Z",
     "start_time": "2023-07-15T07:46:45.758557100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Mexico_data_preprocessing.ipynb',\n 'preprocessing.ipynb',\n 'RSNA_data_preprocessing.ipynb',\n 'test_set_rsna.ipynb']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torchvision.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\David Mexico\\\\Bone age estimation\\\\bone_age_estimation'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "main_dir = os.getcwd()\n",
    "main_dir"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T07:46:52.512629600Z",
     "start_time": "2023-07-15T07:46:52.496976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   id  age  gender  boneage radiologist  year_entry  \\\n0   1  192       0      204         JSA        2019   \n1   2  173       0      192         JSA        2019   \n2   3   48       0       36         JSA        2019   \n3   4   48       1       60         JSA        2019   \n4   5  163       0      162         JSA        2019   \n\n                                             path  exists  \n0  data\\Mexico_private_dataset\\preprocessed\\1.png    True  \n1  data\\Mexico_private_dataset\\preprocessed\\2.png    True  \n2  data\\Mexico_private_dataset\\preprocessed\\3.png    True  \n3  data\\Mexico_private_dataset\\preprocessed\\4.png    True  \n4  data\\Mexico_private_dataset\\preprocessed\\5.png    True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>boneage</th>\n      <th>radiologist</th>\n      <th>year_entry</th>\n      <th>path</th>\n      <th>exists</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>192</td>\n      <td>0</td>\n      <td>204</td>\n      <td>JSA</td>\n      <td>2019</td>\n      <td>data\\Mexico_private_dataset\\preprocessed\\1.png</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>173</td>\n      <td>0</td>\n      <td>192</td>\n      <td>JSA</td>\n      <td>2019</td>\n      <td>data\\Mexico_private_dataset\\preprocessed\\2.png</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>48</td>\n      <td>0</td>\n      <td>36</td>\n      <td>JSA</td>\n      <td>2019</td>\n      <td>data\\Mexico_private_dataset\\preprocessed\\3.png</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>48</td>\n      <td>1</td>\n      <td>60</td>\n      <td>JSA</td>\n      <td>2019</td>\n      <td>data\\Mexico_private_dataset\\preprocessed\\4.png</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>163</td>\n      <td>0</td>\n      <td>162</td>\n      <td>JSA</td>\n      <td>2019</td>\n      <td>data\\Mexico_private_dataset\\preprocessed\\5.png</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df = pd.read_csv(\"data/Mexico_private_dataset/mexico_preprocessed_dataset.csv\")\n",
    "age_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T13:18:25.225051900Z",
     "start_time": "2023-07-13T13:18:25.192228Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Map id to path\n",
    "age_df['path'] = age_df['id'].map(lambda x: os.path.join(main_dir,\n",
    "                                                         'data',\n",
    "                                                         'rsna-bone-age',\n",
    "                                                         'training',\n",
    "                                                         'preprocessed',\n",
    "                                                         '{}.png'.format(x)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 images found of 341 total\n"
     ]
    }
   ],
   "source": [
    "# Checking if all the images exist\n",
    "age_df['exists'] = age_df['path'].map(os.path.exists)\n",
    "print(age_df['exists'].sum(), 'images found of', age_df.shape[0], 'total')\n",
    "# Drop row if exist column is false does not exist\n",
    "age_df = age_df[age_df['exists']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T13:18:27.205485700Z",
     "start_time": "2023-07-13T13:18:27.185237400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert boolean male values to gender 0(male) and 1(female)\n",
    "age_df['gender'] = age_df['male'].map(lambda x: 0 if x else 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "age_df = pd.read_csv(\"data/mexico_private_dataset/mexico_complete_dataset.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T07:46:52.560516800Z",
     "start_time": "2023-07-15T07:46:52.514876700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "448"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boneage_mean = age_df['boneage'].mean()\n",
    "boneage_div = 2 * age_df['boneage'].std()\n",
    "# we don't want normalization for now\n",
    "boneage_mean = 0\n",
    "boneage_div = 1.0\n",
    "age_df['boneage_zscore'] = age_df['boneage'].map(lambda x: (x - boneage_mean) / boneage_div)\n",
    "age_df.dropna(inplace=True)\n",
    "\n",
    "# Creating bins for the boneage\n",
    "age_df['boneage_category'] = pd.cut(age_df['boneage'], 10)\n",
    "len(age_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T07:47:48.814248400Z",
     "start_time": "2023-07-15T07:47:48.806081600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Splitting the data into train and validation based on the boneage_category\n",
    "age_df['boneage_category'] = pd.cut(age_df['boneage'], 10)\n",
    "train_df, valid_df = train_test_split(age_df,\n",
    "                                          test_size=0.10,\n",
    "                                          random_state=2018,\n",
    "                                          stratify=age_df['boneage_category'])\n",
    "# Saving the dataframe with boneage, path, id and gender information\n",
    "train_df = train_df[['id', 'boneage', 'path', 'gender']]\n",
    "validation_df = valid_df[['id', 'boneage', 'path', 'gender']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T07:47:06.655430100Z",
     "start_time": "2023-07-15T07:47:06.632077800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# save dataframe not index\n",
    "train_df.to_csv('data/Mexico_private_dataset/train_preprocessed.csv', index=False)\n",
    "validation_df.to_csv('data/Mexico_private_dataset/valid_preprocessed.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T07:47:09.659575800Z",
     "start_time": "2023-07-15T07:47:09.641889100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(403, 45)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(validation_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T07:47:27.878651100Z",
     "start_time": "2023-07-15T07:47:27.824312900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "448"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df) + len(validation_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T07:47:28.291855400Z",
     "start_time": "2023-07-15T07:47:28.281652400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/rsna-bone-age/training/train_df.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_50 = train_df.head(50)\n",
    "train_3 = train_df.head(3)\n",
    "train_10 = train_df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot the images using the path column in the train_50 dataframe and plot 4 image per row\n",
    "row, columns = 10, 5\n",
    "fig, ax = plt.subplots(10, 5, figsize=(20, 30))\n",
    "for i, idx in enumerate(train_50.index):\n",
    "    path = train_50['path'].loc[idx]\n",
    "    ax[i // columns, i % columns].imshow(plt.imread(path), cmap='gray')\n",
    "    ax[i // columns, i % columns].axis('off')\n",
    "    ax[i // columns, i % columns].set_title('Age:{}'.format(train_50['boneage'].loc[idx]))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# albumentation transformation\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(1024, 1024),\n",
    "    A.CLAHE(),\n",
    "    ToTensorV2()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, idx in enumerate(train_50.index):\n",
    "    path = train_50['path'].loc[idx]\n",
    "    # read image and add transformation\n",
    "    img = cv2.imread(path)\n",
    "    transformed = transform(image=img)['image']\n",
    "    # plot both img and transformed side by side\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[1].imshow(transformed.permute(1, 2, 0), cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Transformed Image')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clip the scan based on the first and last non-zero pixels\n",
    "def clip_image(img, plot=False):\n",
    "    # sum across the rows and columns\n",
    "    row_sum = np.sum(img, axis=1)\n",
    "    col_sum = np.sum(img, axis=0)\n",
    "    # find the first and last non-zero values\n",
    "    row_first, col_first = np.argmax(row_sum > 0), np.argmax(col_sum > 0)\n",
    "    row_last, col_last = len(row_sum) - np.argmax(row_sum[::-1] > 0), len(col_sum) - np.argmax(col_sum[::-1] > 0)\n",
    "    # clip the image\n",
    "    img = img[row_first:row_last, col_first:col_last]\n",
    "    if plot:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the image before and after clipping\n",
    "for i, idx in enumerate(train_10.index):\n",
    "    path = train_10['path'].loc[idx]\n",
    "    # read image and add transformation\n",
    "    img = cv2.imread(path, 0)\n",
    "    clipped = clip_image(img, plot=False)\n",
    "    # plot both img and transformed side by side\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[1].imshow(clipped, cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Clipped Image')\n",
    "    plt.title('ID:{}'.format(train_10['id'].loc[idx]))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# histogram equalization and clipping\n",
    "def equalize_image(img, plot=False):\n",
    "    # histogram equalization\n",
    "    img = cv2.equalizeHist(img)\n",
    "    if plot:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return img\n",
    "\n",
    "# plot the intensity histogram and image side by side\n",
    "def plot_intensity_hist(img):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax[0].hist(img.ravel(), bins=256)\n",
    "    ax[0].set_title('Intensity Histogram')\n",
    "    ax[0].set_xlabel('Intensity')\n",
    "    ax[0].set_ylabel('Count')\n",
    "    ax[1].imshow(img, cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Image')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = train_3\n",
    "for i, idx in enumerate(train.index):\n",
    "    path = train['path'].loc[idx]\n",
    "    # read image and add transformation\n",
    "    img = cv2.imread(path, 0)\n",
    "    plot_intensity_hist(img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "age_df = pd.read_csv(\"data/rsna-bone-age/training/train.csv\")\n",
    "age_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessed_id = glob.glob(\"data/rsna-bone-age/training/preprocessed/*.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessed_id = [int(os.path.basename(i).split(\".\")[0]) for i in preprocessed_id]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(preprocessed_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessed_df = age_df.loc[age_df['id'].isin(preprocessed_id)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(preprocessed_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Brightness of the image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import exposure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = glob.glob(\"data/rsna-bone-age/training/preprocessed/2014.*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image_path in images:\n",
    "    i += 1\n",
    "    image = Image.open(image_path)\n",
    "    clahe = exposure.equalize_adapthist(np.array(image.convert(\"L\")))\n",
    "\n",
    "    clahe_image = (clahe * 255).astype(np.uint8)\n",
    "    clahe_image = Image.fromarray(clahe_image)\n",
    "\n",
    "    image.save(os.path.join(\"data/rsna-bone-age/training/preprocessed_clahe/\",os.path.basename(image_path)))\n",
    "    clahe_image.save(os.path.join(\"data/rsna-bone-age/training/preprocessed_clahe/\", \"__\" + os.path.basename(image_path)))\n",
    "    if i == 100:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
